from pydantic import BaseModel, Field


class SearchResult(BaseModel):
    """Search result for legal document chunks.
    
    Field names kept for backward compatibility:
    - title → section_title (for chunked sections)
    - feed_author → jurisdiction (e.g., "Lagos State")
    - feed_name → document_title (e.g., "Lagos State Tenancy Law 2011")
    - article_author → document_type or empty list
    - url → document_id (unique identifier for the document)
    """
    title: str = Field(default="", description="Section title of the document chunk")
    feed_author: str | None = Field(default=None, description="Jurisdiction (e.g., 'Lagos State')")
    feed_name: str | None = Field(default=None, description="Document title (e.g., 'Lagos State Tenancy Law 2011')")
    article_author: list[str] | None = Field(default=None, description="Document type or related metadata")
    url: str | None = Field(default=None, description="Document ID (unique identifier for the document)")
    chunk_text: str | None = Field(default=None, description="Text content of the document chunk")
    score: float = Field(default=0.0, description="Relevance score of the document chunk")


class UniqueTitleRequest(BaseModel):
    """Request model for unique document section titles search."""
    query_text: str = Field(default="", description="The user query text")
    feed_author: str | None = Field(default=None, description="Filter by jurisdiction (e.g., 'Lagos State')")
    feed_name: str | None = Field(default=None, description="Filter by document title")
    article_author: list[str] | None = Field(default=None, description="Filter by document type")
    title_keywords: str | None = Field(
        default=None, description="Keywords or phrase to match in section title"
    )
    limit: int = Field(default=5, description="Number of results to return")


class UniqueTitleResponse(BaseModel):
    results: list[SearchResult] = Field(
        default_factory=list, description="List of unique title search results"
    )


class AskRequest(BaseModel):
    """Request model for asking questions about legal documents."""
    query_text: str = Field(default="", description="The user query text")
    session_id: str | None = Field(
        default=None, description="Session ID to query against uploaded document. If provided, searches both uploaded document and reference law."
    )
    feed_author: str | None = Field(default=None, description="Filter by jurisdiction (e.g., 'Lagos State')")
    feed_name: str | None = Field(default=None, description="Filter by document title")
    article_author: list[str] | None = Field(default=None, description="Filter by document type")
    title_keywords: str | None = Field(
        default=None, description="Keywords or phrase to match in section title"
    )
    limit: int = Field(default=5, description="Number of results to return")
    provider: str = Field(default="natlas", description="The LLM provider to use for generation (N-ATLaS)")
    model: str | None = Field(
        default=None, description="The specific model to use for the provider, if applicable"
    )


class AskResponse(BaseModel):
    query: str = Field(default="", description="The original query text")
    provider: str = Field(default="", description="The LLM provider used for generation")
    answer: str = Field(default="", description="Generated answer from the LLM")
    sources: list[SearchResult] = Field(
        default_factory=list, description="List of source documents used in generation"
    )
    model: str | None = Field(
        default=None, description="The specific model used by the provider, if available"
    )
    finish_reason: str | None = Field(
        default=None, description="The reason why the generation finished, if available"
    )


class AskStreamingChunk(BaseModel):
    delta: str = Field(default="", description="Partial text generated by the LLM")


class AskStreamingResponse(BaseModel):
    query: str = Field(default="", description="The original query text")
    provider: str = Field(default="", description="The LLM provider used for generation")
    chunks: list[AskStreamingChunk] = Field(
        default_factory=list, description="Streamed chunks of generated text"
    )

class UploadAgreementResponse(BaseModel):
    """Response model for agreement upload and analysis."""
    session_id: str = Field(description="Session ID for tracking this uploaded document")
    document_id: str = Field(description="Document ID for querying this specific document")
    extracted_text: str = Field(description="Text extracted from the uploaded file")
    analysis: str = Field(description="Legal analysis of the agreement")
    flagged_clauses: list[str] = Field(
        default_factory=list, description="List of clauses that may violate the law"
    )
    risks: list[str] = Field(
        default_factory=list, description="List of identified risks"
    )
    summary: str = Field(default="", description="Overall summary of the agreement")
    recommendations: str = Field(default="", description="Recommendations for the tenant")
    sources: list[str] = Field(
        default_factory=list, description="Legal document sources used in analysis"
    )
    language: str = Field(default="en", description="Language code used for analysis")
    expires_at: str = Field(description="ISO timestamp when this session/document will expire")


class VoiceAskRequest(BaseModel):
    """Request model for voice-based question-answering."""
    session_id: str | None = Field(
        default=None, description="Session ID to query against uploaded document. If provided, searches both uploaded document and reference law."
    )
    language: str = Field(
        default="en",
        description="Language code: 'yo' (Yoruba), 'ha' (Hausa), 'ig' (Igbo), 'en' (Nigerian Accented English)"
    )
    limit: int = Field(default=5, description="Number of context documents to retrieve")
    provider: str = Field(default="natlas", description="LLM provider to use (default: natlas)")


class VoiceAskResponse(BaseModel):
    """Response model for voice-based question-answering."""
    transcribed_text: str = Field(description="Transcribed text from audio")
    language_detected: str = Field(description="Language code detected/used")
    query: str = Field(description="The user's query (from transcription)")
    answer: str = Field(description="Generated answer from the LLM")
    sources: list[SearchResult] = Field(
        default_factory=list, description="Source documents used in generation"
    )
    model: str | None = Field(default=None, description="Model used for generation")
